\chapter{Introduction}
\label{chap:intro}

\textbf{by Bastian Boll} \\

There is a constant need to generate subtitles for video. For large video quantities such as on sites like youtube, machine learning systems have been employed to perform this task for some time now. However, solving the general speech-to-text problem is challenging and hence, human transcription is still used in contexts where subtitles need to be of consistent quality.

In this work, we aim to solve a related problem: given an audio file $A$ and a finished transcript $\mathcal{T}$, we try to compute time alignment information. Let $\mathcal{T}$ be an $l$-tuple of words and $A$ be a spoken-word audio signal with known length such that every word $w$ in $\mathcal{T}$ occurs in $A$ at time $t_w$ . We try to find the mapping
\begin{align*}
	f&\colon\textrm{Transcripts}_l\to\R^l\\
	\mathcal{T}&\mapsto f(\mathcal{T})\textrm{ such that }(f(\mathcal{T}))_w=t_w
\end{align*}
Because the transcript is given, this problem is easier to solve than general speech-to-text. Specifically, a respective model does not need to solve the tasks addressed by the language model in a typical speech-to-text system.

However, a good solution for the above problem is still a useful tool in generating subtitles as the tedious and error-prone process of aligning a transcript to the video could be automated.

\section{Survey of the dataset}

\textbf{by Bastian Boll} \\

We use a dataset consisting of ??? \href{https://www.ted.com}{TED-talks}. Part of the metadata for these talks can be found in \href{https://www.kaggle.com/rounakbanik/ted-talks}{a kaggle dataset}. Additional data, such as subtitles and audio files can be aquired from the TED website. Both the subtitles and the audio are permitted to be used for the described purpose by their \href{https://www.ted.com/about/our-organization/our-policies-terms/ted-talks-usage-policy}{usage policy and license}.\\
The dataset contains approximately 560 hours of high quality English spoken audio recordings. Speakers come from a very diverse international pool. The used language is relatively erudite. Both subtitles and transcripts for each talk are human-generated.

\section{Implementation}

\textbf{by Bastian Boll} \\

All presented methods are implemented in Python 3.6 on top of \href{https://www.tensorflow.org/}{Tensorflow 1.4} and \href{http://www.numpy.org/}{numpy}. The source code is available at \url{https://github.com/bbboll/ml_subtitle_align}. The \emph{Readme.md} provides additional information on how to get started.